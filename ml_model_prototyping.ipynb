{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon Reviews - Prediction of Rating and Helpfulness (an NLP Use Case)\n",
    "##  Machine Learning Prototyping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, I have prototyped machine learning model to predict rating and helpfulness of Amazon reviews. For this prototyping, I used 0.5% of Amazon review dataset (~600,000 reviews). To know about how the data is gathered from Amazon S3 bucket and sampled, please see the notebook `amazon_reviews_data_gathering.ipynb`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "* [Text Preprocessing](#tp)\n",
    "* [Sentiment Analysis](#sa)\n",
    "* [Doc2Vec](#dv)\n",
    "* [ML Prototyping: Rating Prediction](#rp)\n",
    "  * [Logistic Regression](#lr)\n",
    "  * [Random Forest](#rf)\n",
    "  * [Multilayer Perceptron](#mlp)\n",
    "* [Dealing with Class Imbalance](#ci)\n",
    "  * [Logistic Regression with Class Wieght Balanced](#ilr)\n",
    "  * [Ranodm Forest with Balanced Dataset](#irf)\n",
    "  * [Multilayer Perceptron with Balanced Dataset](#imlp)\n",
    "* [ML Prototyping: Helpfulness Prediction](#hp)\n",
    "  * [Linear Regression](#lrg)\n",
    "  * [Gradient Boosting Trees](#gbt)  \n",
    "* [Conclusion](#cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a dataframe by reading the file containing subset of amazon review dataset sampled in the notebook \"amazon_reviews_data_gathering.ipynb\"\n",
    "# Define the schema of the dataframe to be created\n",
    "from pyspark.sql.types import StructType, StructField\n",
    "from pyspark.sql.types import DoubleType, IntegerType, StringType, DateType\n",
    "\n",
    "schema = StructType([\n",
    "      StructField('marketplace', StringType()),\n",
    "      StructField('customer_id', StringType()),\n",
    "      StructField('review_id', StringType()),\n",
    "      StructField('product_id', StringType()),\n",
    "      StructField('product_parent', StringType()),\n",
    "      StructField('product_title', StringType()),\n",
    "      StructField('product_category', StringType()),\n",
    "      StructField('star_rating', IntegerType()),\n",
    "      StructField('helpful_votes', IntegerType()),\n",
    "      StructField('total_votes', IntegerType()),\n",
    "      StructField('vine', StringType()),\n",
    "      StructField('verified_purchase', StringType()),\n",
    "      StructField('review_headline', StringType()),\n",
    "      StructField('review_body', StringType()),\n",
    "      StructField('review_date', DateType())\n",
    "])\n",
    "\n",
    "review_subset_df = (sqlContext.read.format('com.databricks.spark.csv')\n",
    "             .schema(schema)\n",
    "             .option(\"inferSchema\", False)\n",
    "             .option(\"header\", True)\n",
    "             .load(\"dbfs:/FileStore/review_df_sample/review_df_sample.csv\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">4</span><span class=\"ansired\">]: </span>DataFrame[marketplace: string, customer_id: string, review_id: string, product_id: string, product_parent: string, product_title: string, product_category: string, star_rating: int, helpful_votes: int, total_votes: int, vine: string, verified_purchase: string, review_headline: string, review_body: string, review_date: date]</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "review_subset_df.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='tp'></a>\n",
    "## Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "review_rating_helpful_df = review_subset_df.select('review_body', 'star_rating', 'helpful_votes', 'total_votes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Total words in the corpus: 27913663\n",
       "Unique words in the corpus: 692705\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Number of words in review_body corpus\n",
    "review_body_list = review_rating_helpful_df.select('review_body').rdd.map(lambda row : row[0]).collect()\n",
    "word_corpus = []\n",
    "for i in review_body_list:\n",
    "  word_corpus.extend(i.split())\n",
    "print (\"Total words in the corpus: {}\".format(len(word_corpus)))\n",
    "print (\"Unique words in the corpus: {}\".format(len(set(word_corpus))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">{&apos;N&apos;, &apos;久&apos;, &apos;하&apos;, &apos;⅔&apos;, &apos;煦&apos;, &apos;■&apos;, &apos;y&apos;, &apos;û&apos;, &apos;电&apos;, &apos;ж&apos;, &apos;И&apos;, &apos;情&apos;, &apos;🐝&apos;, &apos;🎉&apos;, &apos;만&apos;, &apos;У&apos;, &apos;″&apos;, &apos;南&apos;, &apos;t&apos;, &apos;ĺ&apos;, &apos;◕&apos;, &apos;B&apos;, &apos;i&apos;, &apos;ａ&apos;, &apos;论&apos;, &apos;💕&apos;, &apos;😙&apos;, &apos;相&apos;, &apos;\\x82&apos;, &apos;😘&apos;, &apos;🏢&apos;, &apos;道&apos;, &apos;意&apos;, &apos;🌀&apos;, &apos;👧&apos;, &apos;:&apos;, &apos;真&apos;, &apos;📚&apos;, &apos;成&apos;, &apos;o&apos;, &apos;❕&apos;, &apos;—&apos;, &apos;👱&apos;, &apos;摄&apos;, &quot;&apos;&quot;, &apos;¿&apos;, &apos;🏿&apos;, &apos;$&apos;, &apos;💛&apos;, &apos;商&apos;, &apos;📣&apos;, &apos;ш&apos;, &apos;p&apos;, &apos;细&apos;, &apos;虽&apos;, &apos;🐺&apos;, &apos;ú&apos;, &apos;流&apos;, &apos;😖&apos;, &apos;往&apos;, &apos;了&apos;, &apos;忘&apos;, &apos;냅&apos;, &apos;👵&apos;, &apos;б&apos;, &apos;Р&apos;, &apos;라&apos;, &apos;ｌ&apos;, &apos;🏽&apos;, &apos;м&apos;, &apos;\\x94&apos;, &apos;🐤&apos;, &apos;🏼&apos;, &apos;f&apos;, &apos;些&apos;, &apos;🕔&apos;, &apos;站&apos;, &apos;出&apos;, &apos;🕝&apos;, &apos;¾&apos;, &apos;Ç&apos;, &apos;😐&apos;, &apos;🙊&apos;, &apos;ｍ&apos;, &apos;ئ&apos;, &apos;现&apos;, &apos;ð&apos;, &apos;좋&apos;, &apos;🚗&apos;, &apos;\\x85&apos;, &apos;;&apos;, &apos;灯&apos;, &apos;ё&apos;, &apos;🕖&apos;, &apos;주&apos;, &apos;书&apos;, &apos;育&apos;, &apos;运&apos;, &apos;太&apos;, &apos;😟&apos;, &apos;№&apos;, &apos;刻&apos;, &apos;Ō&apos;, &apos;什&apos;, &apos;👏&apos;, &apos;😧&apos;, &apos;间&apos;, &apos;Q&apos;, &apos;💪&apos;, &apos;벨&apos;, &apos;💞&apos;, &apos;覚&apos;, &apos;🐃&apos;, &apos;🎰&apos;, &apos;ش&apos;, &apos;没&apos;, &apos;🏦&apos;, &apos;确&apos;, &apos;°&apos;, &apos;行&apos;, &apos;여&apos;, &apos;ŭ&apos;, &apos;버&apos;, &apos;\\x98&apos;, &apos;خ&apos;, &apos;塵&apos;, &apos;⅛&apos;, &apos;์&apos;, &apos;\\x91&apos;, &apos;!&apos;, &apos;🕞&apos;, &apos;东&apos;, &apos;👗&apos;, &apos;💉&apos;, &apos;霞&apos;, &apos;💯&apos;, &apos;💵&apos;, &apos;щ&apos;, &apos;🐀&apos;, &apos;💑&apos;, &apos;I&apos;, &apos;长&apos;, &apos;👦&apos;, &apos;크&apos;, &apos;ý&apos;, &apos;生&apos;, &apos;😥&apos;, &apos;但&apos;, &apos;Э&apos;, &apos;🐓&apos;, &apos;洱&apos;, &apos;ª&apos;, &apos;当&apos;, &apos;）&apos;, &apos;穢&apos;, &apos;ط&apos;, &apos;🎆&apos;, &apos;👌&apos;, &apos;¥&apos;, &apos;ē&apos;, &apos;邮&apos;, &apos;激&apos;, &apos;\\x81&apos;, &apos;😱&apos;, &apos;乐&apos;, &apos;🐦&apos;, &apos;😣&apos;, &apos;缺&apos;, &apos;🐄&apos;, &apos;音&apos;, &apos;🏻&apos;, &apos;通&apos;, &apos;å&apos;, &apos;✗&apos;, &apos;게&apos;, &apos;清&apos;, &apos;j&apos;, &apos;以&apos;, &apos;☀&apos;, &apos;ි&apos;, &apos;公&apos;, &apos;ß&apos;, &apos;🍭&apos;, &apos;议&apos;, &apos;ο&apos;, &apos;🍬&apos;, &apos;为&apos;, &apos;卖&apos;, &apos;可&apos;, &apos;侧&apos;, &apos;.&apos;, &apos;💘&apos;, &apos;😼&apos;, &apos;🐜&apos;, &apos;′&apos;, &apos;明&apos;, &apos;程&apos;, &apos;🏈&apos;, &apos;H&apos;, &apos;\\u2028&apos;, &apos;🙍&apos;, &apos;咯&apos;, &apos;Ｉ&apos;, &apos;Ÿ&apos;, &apos;ي&apos;, &apos;朋&apos;, &apos;ô&apos;, &apos;É&apos;, &apos;⭐&apos;, &apos;ì&apos;, &apos;✘&apos;, &apos;&gt;&apos;, &apos;×&apos;, &apos;🎺&apos;, &apos;🐨&apos;, &apos;😌&apos;, &apos;国&apos;, &apos;的&apos;, &apos;ū&apos;, &apos;么&apos;, &apos;方&apos;, &apos;多&apos;, &apos;ｒ&apos;, &apos;利&apos;, &apos;1&apos;, &apos;航&apos;, &apos;💮&apos;, &apos;够&apos;, &apos;👶&apos;, &apos;🙀&apos;, &apos;용&apos;, &apos;🎤&apos;, &apos;ƒ&apos;, &apos;는&apos;, &apos;🆓&apos;, &apos;😯&apos;, &apos;\\uef01&apos;, &apos;v&apos;, &apos;Д&apos;, &apos;坛&apos;, &apos;😡&apos;, &apos;ج&apos;, &apos;н&apos;, &apos;в&apos;, &apos;￼&apos;, &apos;د&apos;, &apos;_&apos;, &apos;ğ&apos;, &apos;😩&apos;, &apos;动&apos;, &apos;🎊&apos;, &apos;Л&apos;, &apos;他&apos;, &apos;ï&apos;, &apos;🎹&apos;, &apos;🐏&apos;, &apos;д&apos;, &apos;🎁&apos;, &apos;🙌&apos;, &apos;%&apos;, &apos;~&apos;, &apos;😴&apos;, &apos;Ч&apos;, &apos;🎵&apos;, &apos;=&apos;, &apos;💖&apos;, &apos;²&apos;, &apos;🐒&apos;, &apos;때&apos;, &apos;👪&apos;, &apos;â&apos;, &apos;ｈ&apos;, &apos;ž&apos;, &apos;戴&apos;, &apos;🐰&apos;, &apos;💌&apos;, &apos;火&apos;, &apos;机&apos;, &apos;}&apos;, &apos;О&apos;, &apos;🐆&apos;, &apos;ц&apos;, &apos;于&apos;, &apos;œ&apos;, &apos;希&apos;, &apos;🚶&apos;, &apos;💄&apos;, &apos;E&apos;, &apos;э&apos;, &apos;📖&apos;, &apos;멉&apos;, &apos;³&apos;, &apos;¶&apos;, &apos;£&apos;, &apos;c&apos;, &apos;q&apos;, &apos;🙏&apos;, &apos;😶&apos;, &apos;℅&apos;, &apos;＼&apos;, &apos;老&apos;, &apos;🐢&apos;, &apos;A&apos;, &apos;ò&apos;, &apos;🚮&apos;, &apos;싶&apos;, &apos;汇&apos;, &apos;👑&apos;, &apos;\\x05&apos;, &apos;/&apos;, &apos;直&apos;, &apos;Y&apos;, &apos;卡&apos;, &apos;В&apos;, &apos;💙&apos;, &apos;🐹&apos;, &apos;゜&apos;, &apos;😂&apos;, &apos;🗾&apos;, &apos;浄&apos;, &apos;🕦&apos;, &apos;爽&apos;, &apos;🐂&apos;, &apos;✖&apos;, &apos;\\uf04a&apos;, &apos;障&apos;, &apos;ق&apos;, &apos;🕟&apos;, &apos;질&apos;, &apos;♦&apos;, &apos;\\x8e&apos;, &apos;♖&apos;, &apos;ณ&apos;, &apos;ه&apos;, &apos;煌&apos;, &apos;👀&apos;, &apos;써&apos;, &apos;好&apos;, &apos;도&apos;, &apos;会&apos;, &apos;ｙ&apos;, &apos;🏁&apos;, &apos;*&apos;, &apos;─&apos;, &apos;比&apos;, &apos;脚&apos;, &apos;理&apos;, &apos;🐸&apos;, &apos;미&apos;, &apos;썰&apos;, &apos;¦&apos;, &apos;é&apos;, &apos;😊&apos;, &apos;|&apos;, &apos;\\ue310&apos;, &apos;森&apos;, &apos;ย&apos;, &apos;⌚&apos;, &apos;😨&apos;, &apos;\\x97&apos;, &apos;腻&apos;, &apos;지&apos;, &apos;🕣&apos;, &apos;🌚&apos;, &apos;节&apos;, &apos;😮&apos;, &apos;9&apos;, &apos;W&apos;, &apos;👴&apos;, &apos;你&apos;, &apos;♪&apos;, &apos;\\xa0&apos;, &apos;🐖&apos;, &apos;🙅&apos;, &apos;无&apos;, &apos;😔&apos;, &apos;🗽&apos;, &apos;时&apos;, &apos;ī&apos;, &apos;发&apos;, &apos;가&apos;, &apos;🐔&apos;, &apos;\\x08&apos;, &apos;🐾&apos;, &apos;ك&apos;, &apos;浪&apos;, &apos;更&apos;, &apos;🕢&apos;, &apos;\\x93&apos;, &apos;♤&apos;, &apos;م&apos;, &apos;ث&apos;, &apos;ب&apos;, &apos;½&apos;, &apos;😽&apos;, &apos;з&apos;, &apos;💝&apos;, &apos;요&apos;, &apos;给&apos;, &apos;Â&apos;, &apos;☺&apos;, &apos;写&apos;, &apos;4&apos;, &apos;😋&apos;, &apos;΄&apos;, &apos;着&apos;, &apos;农&apos;, &apos;👠&apos;, &apos;®&apos;, &apos;②&apos;, &apos;,&apos;, &apos;活&apos;, &apos;😄&apos;, &apos;性&apos;, &apos;ر&apos;, &apos;ｔ&apos;, &apos;ء&apos;, &apos;眠&apos;, &apos;Й&apos;, &apos;🐱&apos;, &apos;🏾&apos;, &apos;展&apos;, &apos;비&apos;, &apos;ｄ&apos;, &apos;ｇ&apos;, &apos;👻&apos;, &apos;r&apos;, &apos;\\x84&apos;, &apos;神&apos;, &apos;\\x95&apos;, &apos;¨&apos;, &apos;😠&apos;, &apos;n&apos;, &apos;您&apos;, &apos;🐣&apos;, &apos;✊&apos;, &apos;ч&apos;, &apos;、&apos;, &apos;🌲&apos;, &apos;角&apos;, &apos;о&apos;, &apos;得&apos;, &apos;😻&apos;, &apos;🇺&apos;, &apos;ح&apos;, &apos;✔&apos;, &apos;😒&apos;, &apos;😓&apos;, &apos;L&apos;, &apos;Á&apos;, &apos;ù&apos;, &apos;💓&apos;, &apos;穿&apos;, &apos;💀&apos;, &apos;&#96;&apos;, &apos;\\x1a&apos;, &apos;本&apos;, &apos;身&apos;, &apos;ω&apos;, &apos;🐉&apos;, &apos;声&apos;, &apos;😅&apos;, &apos;🐥&apos;, &apos;😕&apos;, &apos;출&apos;, &apos;أ&apos;, &apos;‧&apos;, &apos;👮&apos;, &apos;🕤&apos;, &apos;‼&apos;, &apos;⬆&apos;, &apos;中&apos;, &apos;称&apos;, &apos;@&apos;, &apos;和&apos;, &apos;要&apos;, &apos;없&apos;, &apos;어&apos;, &apos;ʻ&apos;, &apos;🍁&apos;, &apos;（&apos;, &apos;ㅜ&apos;, &apos;한&apos;, &apos;K&apos;, &apos;🕗&apos;, &apos;蔵&apos;, &apos;네&apos;, &apos;有&apos;, &apos;ع&apos;, &apos;睡&apos;, &apos;{&apos;, &apos;号&apos;, &apos;因&apos;, &apos;U&apos;, &apos;🐞&apos;, &apos;R&apos;, &apos;👂&apos;, &apos;고&apos;, &apos;중&apos;, &apos;🐁&apos;, &apos;\\x92&apos;, &apos;k&apos;, &apos;♡&apos;, &apos;ь&apos;, &apos;这&apos;, &apos;\\u2003&apos;, &apos;s&apos;, &apos;？&apos;, &apos;便&apos;, &apos;🐻&apos;, &apos;\\x8f&apos;, &apos;F&apos;, &apos;͡&apos;, &apos;🐗&apos;, &apos;🐩&apos;, &apos;特&apos;, &apos;Í&apos;, &apos;🏡&apos;, &apos;ó&apos;, &apos;😀&apos;, &apos;»&apos;, &apos;·&apos;, &apos;ｆ&apos;, &apos;🐭&apos;, &apos;데&apos;, &apos;아&apos;, &apos;语&apos;, &apos;ç&apos;, &apos;💔&apos;, &apos;🌋&apos;, &apos;🔪&apos;, &apos;🐡&apos;, &apos;💒&apos;, &apos;🎸&apos;, &apos;5&apos;, &apos;：&apos;, &apos;러&apos;, &apos;🐑&apos;, &apos;😏&apos;, &apos;ü&apos;, &apos;ı&apos;, &apos;🙋&apos;, &apos;ö&apos;, &apos;🎥&apos;, &apos;и&apos;, &apos;õ&apos;, &apos;ｋ&apos;, &apos;👾&apos;, &apos;Ú&apos;, &apos;ř&apos;, &apos;小&apos;, &apos;紧&apos;, &apos;ව&apos;, &apos;👈&apos;, &apos;\\x80&apos;, &apos;友&apos;, &apos;พ&apos;, &apos;💁&apos;, &apos;》&apos;, &apos;Ь&apos;, &apos;📋&apos;, &apos;ｉ&apos;, &apos;来&apos;, &apos;◠&apos;, &apos;”&apos;, &apos;…&apos;, &apos;Ü&apos;, &apos;X&apos;, &apos;😃&apos;, &apos;₩&apos;, &apos;«&apos;, &apos;x&apos;, &apos;\\u3000&apos;, &apos;▽&apos;, &apos;坚&apos;, &apos;0&apos;, &apos;\\x8c&apos;, &apos;\\x9f&apos;, &apos;á&apos;, &apos;^&apos;, &apos;😁&apos;, &apos;都&apos;, &apos;Ó&apos;, &apos;3&apos;, &apos;🏭&apos;, &apos;❅&apos;, &apos;🌴&apos;, &apos;愉&apos;, &apos;و&apos;, &apos;\\x90&apos;, &apos;ز&apos;, &apos;普&apos;, &apos;ю&apos;, &apos;š&apos;, &apos;Ｍ&apos;, &apos;\\x8a&apos;, &apos;閑&apos;, &apos;也&apos;, &apos;d&apos;, &apos;P&apos;, &apos;z&apos;, &apos;🐪&apos;, &apos;−&apos;, &apos;무&apos;, &apos;裏&apos;, &apos;工&apos;, &apos;&lt;&apos;, &apos;無&apos;, &apos;厭&apos;, &apos;🐧&apos;, &apos;\\x88&apos;, &apos;랑&apos;, &apos;い&apos;, &apos;с&apos;, &apos;价&apos;, &apos;▬&apos;, &apos;👎&apos;, &apos;ก&apos;, &apos;█&apos;, &apos;u&apos;, &apos;🗿&apos;, &apos;💬&apos;, &apos;💚&apos;, &apos;ã&apos;, &apos;6&apos;, &apos;+&apos;, &apos;🌝&apos;, &apos;،&apos;, &apos;г&apos;, &apos;🏀&apos;, &apos;😆&apos;, &apos;累&apos;, &apos;😝&apos;, &apos;서&apos;, &apos;很&apos;, &apos;T&apos;, &apos;🎶&apos;, &apos;表&apos;, &apos;7&apos;, &apos;滑&apos;, &apos;👨&apos;, &apos;😺&apos;, &apos;\\x7f&apos;, &apos;더&apos;, &apos;👩&apos;, &apos;🏰&apos;, &apos;•&apos;, &apos;Б&apos;, &apos;地&apos;, &apos;💗&apos;, &apos;纯&apos;, &apos;佩&apos;, &apos;ʖ&apos;, &apos;等&apos;, &apos;#&apos;, &apos;있&apos;, &apos;🕑&apos;, &apos;я&apos;, &apos;👙&apos;, &apos;🐲&apos;, &apos;🐎&apos;, &apos;티&apos;, &apos;8&apos;, &apos;👷&apos;, &apos;🐊&apos;, &apos;🔟&apos;, &apos;―&apos;, &apos;\\x10&apos;, &apos;感&apos;, &apos;g&apos;, &apos;已&apos;, &apos;💃&apos;, &apos;用&apos;, &apos;ة&apos;, &apos;哦&apos;, &apos;п&apos;, &apos;🔥&apos;, &apos;●&apos;, &apos;．&apos;, &apos;🐫&apos;, &apos;💎&apos;, &apos;˜&apos;, &apos;👺&apos;, &apos;一&apos;, &apos;😢&apos;, &apos;Ϟ&apos;, &apos;超&apos;, &apos;&amp;&apos;, &apos;🐛&apos;, &apos;ø&apos;, &apos;자&apos;, &apos;★&apos;, &apos;к&apos;, &apos;🕘&apos;, &apos;¢&apos;, &apos;欠&apos;, &apos;😷&apos;, &apos;º&apos;, &apos;?&apos;, &apos;🌛&apos;, &apos;è&apos;, &apos;👐&apos;, &apos;ා&apos;, &apos;却&apos;, &apos;那&apos;, &apos;🐯&apos;, &apos;해&apos;, &apos;л&apos;, &apos;ｂ&apos;, &apos;格&apos;, &apos;Е&apos;, &apos;Н&apos;, &apos;受&apos;, &apos;弹&apos;, &apos;С&apos;, &apos;④&apos;, &apos;よ&apos;, &apos;简&apos;, &apos;ｅ&apos;, &apos;니&apos;, &apos;¯&apos;, &apos;🐷&apos;, &apos;🐠&apos;, &apos;面&apos;, &apos;佳&apos;, &apos;🕠&apos;, &apos;鬼&apos;, &apos;ä&apos;, &apos;า&apos;, &apos;在&apos;, &apos;能&apos;, &apos;🎧&apos;, &apos;‘&apos;, &apos;🙎&apos;, &apos;🎇&apos;, &apos;ل&apos;, &apos;ㅋ&apos;, &apos;보&apos;, &apos;品&apos;, &apos;🐘&apos;, &apos;커&apos;, &apos;层&apos;, &apos;不&apos;, &apos;🎷&apos;, &apos;🍫&apos;, &apos;💋&apos;, &apos;¤&apos;, &apos;ص&apos;, &apos;А&apos;, &apos;😬&apos;, &apos;🔝&apos;, &apos;😫&apos;, &apos;К&apos;, &apos;Ñ&apos;, &apos;🎮&apos;, &apos;😳&apos;, &apos;)&apos;, &apos;Š&apos;, &apos;\\u193e&apos;, &apos;¡&apos;, &apos;🕡&apos;, &apos;而&apos;, &apos;ë&apos;, &apos;汚&apos;, &apos;😉&apos;, &apos;🐟&apos;, &apos;П&apos;, &apos;구&apos;, &apos;D&apos;, &apos;误&apos;, &apos;💏&apos;, &apos;Т&apos;, &apos;р&apos;, &apos;¹&apos;, &apos;🐮&apos;, &apos;😤&apos;, &apos;十&apos;, &apos;￣&apos;, &apos;新&apos;, &apos;ｎ&apos;, &apos;ت&apos;, &apos;O&apos;, &apos;募&apos;, &apos;ｖ&apos;, &apos;č&apos;, &apos;’&apos;, &apos;！&apos;, &apos;🐬&apos;, &apos;🌈&apos;, &apos;€&apos;, &apos;③&apos;, &apos;🎻&apos;, &apos;ď&apos;, &apos;🎿&apos;, &apos;法&apos;, &apos;e&apos;, &apos;(&apos;, &apos;🌟&apos;, &apos;画&apos;, &apos;，&apos;, &apos;ٍ&apos;, &apos;辉&apos;, &apos;ග&apos;, &apos;🐐&apos;, &apos;a&apos;, &apos;美&apos;, &apos;知&apos;, &apos;ร&apos;, &apos;🕙&apos;, &apos;🚫&apos;, &apos;👍&apos;, &apos;l&apos;, &apos;너&apos;, &apos;т&apos;, &apos;🐕&apos;, &apos;V&apos;, &apos;Ы&apos;, &apos;🐌&apos;, &apos;教&apos;, &apos;固&apos;, &apos;🕥&apos;, &apos;ñ&apos;, &apos;🐈&apos;, &apos;😎&apos;, &apos;😍&apos;, &apos;👰&apos;, &apos;w&apos;, &apos;💩&apos;, &apos;高&apos;, &apos;💟&apos;, &apos;х&apos;, &apos;❇&apos;, &apos;👟&apos;, &apos;🕒&apos;, &apos;足&apos;, &apos;沉&apos;, &apos;🕓&apos;, &apos;ы&apos;, &apos;😸&apos;, &apos;♥&apos;, &apos;ｓ&apos;, &apos;接&apos;, &apos;“&apos;, &apos;™&apos;, &apos;ف&apos;, &apos;💨&apos;, &apos;我&apos;, &apos;▫&apos;, &apos;🍵&apos;, &apos;́&apos;, &apos;а&apos;, &apos;ê&apos;, &apos;🇸&apos;, &apos;굿&apos;, &apos;😜&apos;, &apos;🔰&apos;, &apos;哈&apos;, &apos;올&apos;, &apos;S&apos;, &apos;🕚&apos;, &apos;\\\\&apos;, &apos;이&apos;, &apos;ا&apos;, &apos;😛&apos;, &apos;İ&apos;, &apos;光&apos;, &apos;제&apos;, &apos;î&apos;, &apos; &apos;, &apos;🙆&apos;, &apos;C&apos;, &apos;😪&apos;, &apos;M&apos;, &apos;😑&apos;, &apos;😵&apos;, &apos;긴&apos;, &apos;△&apos;, &apos;þ&apos;, &apos;\\ue311&apos;, &apos;س&apos;, &apos;ذ&apos;, &apos;❤&apos;, &apos;🏆&apos;, &apos;啊&apos;, &apos;ｏ&apos;, &apos;影&apos;, &apos;别&apos;, &apos;实&apos;, &apos;满&apos;, &apos;🕕&apos;, &apos;😹&apos;, &apos;✌&apos;, &apos;👿&apos;, &apos;재&apos;, &apos;⅓&apos;, &apos;\\x9c&apos;, &apos;\\x1f&apos;, &apos;ş&apos;, &apos;Ã&apos;, &apos;🐵&apos;, &apos;쁘&apos;, &apos;]&apos;, &apos;¼&apos;, &apos;再&apos;, &apos;ツ&apos;, &apos;æ&apos;, &apos;😚&apos;, &apos;ị&apos;, &apos;사&apos;, &apos;그&apos;, &apos;🏧&apos;, &apos;余&apos;, &apos;´&apos;, &apos;点&apos;, &apos;味&apos;, &apos;透&apos;, &apos;로&apos;, &apos;次&apos;, &apos;稳&apos;, &apos;😞&apos;, &apos;😰&apos;, &apos;🐇&apos;, &apos;单&apos;, &apos;\\x8d&apos;, &apos;ｃ&apos;, &apos;👣&apos;, &apos;🗼&apos;, &apos;払&apos;, &apos;产&apos;, &apos;✨&apos;, &apos;🐋&apos;, &apos;错&apos;, &apos;👹&apos;, &apos;±&apos;, &apos;○&apos;, &apos;😗&apos;, &apos;过&apos;, &apos;被&apos;, &apos;◆&apos;, &apos;￥&apos;, &apos;Z&apos;, &apos;常&apos;, &apos;m&apos;, &apos;️&apos;, &apos;න&apos;, &apos;ｗ&apos;, &apos;做&apos;, &apos;🐙&apos;, &apos;ō&apos;, &apos;b&apos;, &apos;ට&apos;, &apos;\\x9d&apos;, &apos;-&apos;, &apos;😭&apos;, &apos;[&apos;, &apos;ن&apos;, &apos;朽&apos;, &apos;2&apos;, &apos;。&apos;, &apos;度&apos;, &apos;à&apos;, &apos;ض&apos;, &apos;🎓&apos;, &apos;词&apos;, &apos;\\x15&apos;, &apos;у&apos;, &apos;静&apos;, &apos;买&apos;, &apos;🐼&apos;, &apos;谓&apos;, &apos;J&apos;, &apos;分&apos;, &apos;🏠&apos;, &apos;\\ufeff&apos;, &apos;🔜&apos;, &apos;е&apos;, &apos;①&apos;, &apos;h&apos;, &apos;💜&apos;, &apos;🗻&apos;, &apos;🐴&apos;, &apos;í&apos;, &apos;觉&apos;, &apos;😾&apos;, &apos;心&apos;, &apos;G&apos;, &apos;所&apos;, &apos;是&apos;, &apos;М&apos;, &apos;然&apos;, &apos;스&apos;, &apos;民&apos;, &apos;👊&apos;, &apos;ى&apos;, &apos;外&apos;, &apos;͜&apos;, &apos;望&apos;, &apos;غ&apos;, &apos;개&apos;, &apos;‿&apos;, &apos;§&apos;, &apos;💲&apos;, &apos;©&apos;, &apos;й&apos;, &apos;🐶&apos;, &apos;입&apos;, &apos;\\u200b&apos;, &apos;😦&apos;, &apos;🐳&apos;, &apos;문&apos;, &apos;–&apos;, &apos;☠&apos;, &apos;叫&apos;, &apos;😇&apos;, &apos;☼&apos;, &apos;囧&apos;, &apos;☆&apos;, &apos;&quot;&apos;, &apos;😈&apos;, &apos;\\x99&apos;, &apos;宜&apos;, &apos;다&apos;, &apos;ф&apos;, &apos;凑&apos;, &apos;👉&apos;}\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# set of characters in review body\n",
    "chr_set = set()\n",
    "for review in review_body_list:\n",
    "  chr_set.update(list(review))\n",
    "print(chr_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen in the above output, there are many unwanted characters, which need to be removed. The following cleaning is performed on review text.\n",
    "- lower casing of the text\n",
    "- Stripping html tags\n",
    "- stripiing punctuation\n",
    "- stripping multiple white spaces\n",
    "- stripping numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gensim.parsing.preprocessing as gsp\n",
    "from pyspark.sql.functions import udf\n",
    "from gensim import utils\n",
    "import re\n",
    "\n",
    "# Perform following cleaning tasks on each review\n",
    "cleaning_tasks = [\n",
    "           gsp.strip_tags, \n",
    "           gsp.strip_punctuation,\n",
    "           gsp.strip_multiple_whitespaces,\n",
    "           gsp.strip_numeric\n",
    "          ]\n",
    "\n",
    "def text_preprocessing(df_row):\n",
    "  '''Takes in a text and preprocess/clean it for NLP'''\n",
    "  review_txt = df_row[0]\n",
    "  review_txt = review_txt.lower()\n",
    "  review_txt = utils.to_unicode(review_txt)\n",
    "  for task in cleaning_tasks:\n",
    "      review_txt = task(review_txt)\n",
    "  review_txt = re.sub(r'[^a-zA-Z\\s]', \"\", review_txt)\n",
    "  return (review_txt, df_row[1], df_row[2], df_row[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clean_review_rating_helpful_df = review_rating_helpful_df.rdd.map(lambda x : text_preprocessing(x)).toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Rename the columns as _1 and _2 are not descriptive\n",
    "clean_review_rating_helpful_df = (clean_review_rating_helpful_df.withColumnRenamed(\"_1\", \"review_body\")\n",
    "                                  .withColumnRenamed(\"_2\", \"star_rating\")\n",
    "                                  .withColumnRenamed(\"_3\", \"helpful_votes\")\n",
    "                                  .withColumnRenamed(\"_4\", \"total_votes\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">{&apos;w&apos;, &apos;y&apos;, &apos;h&apos;, &apos;t&apos;, &apos;f&apos;, &apos;d&apos;, &apos;z&apos;, &apos;i&apos;, &apos;g&apos;, &apos;v&apos;, &apos;o&apos;, &apos;q&apos;, &apos;c&apos;, &apos;u&apos;, &apos; &apos;, &apos;e&apos;, &apos;r&apos;, &apos;a&apos;, &apos;m&apos;, &apos;j&apos;, &apos;b&apos;, &apos;x&apos;, &apos;n&apos;, &apos;l&apos;, &apos;p&apos;, &apos;k&apos;, &apos;s&apos;}\n",
       "27\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check character set in review body after cleaning\n",
    "review_body_list_2 = clean_review_rating_helpful_df.select('review_body').rdd.map(lambda row : row[0]).collect()\n",
    "chr_set = set()\n",
    "for review in review_body_list_2:\n",
    "  chr_set.update(list(review))\n",
    "print(chr_set)\n",
    "print(len(chr_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Total words in the corpus after cleaning: 28122904\n",
       "Unique words in the corpus cleaning: 177047\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Number of words in review_body corpus after cleaning\n",
    "word_corpus = []\n",
    "for i in review_body_list_2:\n",
    "  word_corpus.extend(i.split())\n",
    "print (\"Total words in the corpus after cleaning: {}\".format(len(word_corpus)))\n",
    "print (\"Unique words in the corpus cleaning: {}\".format(len(set(word_corpus))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Positive, Negative and Neutral Class Based on Star Rating\n",
    "A model that predicts whether a review is positive, negative or neutral will be trained. Star rating of 5 and 4 will be considered as positive, 3 as neutral and 1 and 2 as negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.functions import when\n",
    "clean_review_rating_helpful_df = (clean_review_rating_helpful_df.withColumn(\"review_category\", \n",
    "                                                when(clean_review_rating_helpful_df.star_rating.isin(5, 4), 'positive')\n",
    "                                                .when(clean_review_rating_helpful_df.star_rating.isin(1, 2), 'negative')\n",
    "                                                .otherwise('neutral')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sa'></a>\n",
    "## Sentiment Analysis with TextBlob\n",
    "In the following section, the sentiment of each review is determined and compared with star rating. TextBlob is an open-source library for sentiment analysis. The polarity score given by TextBlob is a float within the range [-1.0, 1.0]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get polarity of each review\n",
    "from textblob import TextBlob\n",
    "def polarity(df_row):\n",
    "    review_txt = df_row[0]\n",
    "    return (review_txt, df_row[1], df_row[4], round(TextBlob(review_txt).polarity, 3))\n",
    "polarity_df = clean_review_rating_helpful_df.rdd.map(lambda x : polarity(x)).toDF()\n",
    "polarity_df = (polarity_df\n",
    "               .withColumnRenamed(\"_1\", \"review_body\")\n",
    "               .withColumnRenamed(\"_2\", \"star_rating\")\n",
    "               .withColumnRenamed(\"_3\", \"review_category\")\n",
    "               .withColumnRenamed(\"_4\", \"polarity\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Positive, Negative and Neutral Class Based on Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Assign a sentiment to each review based on polarity value\n",
    "polarity_df = (polarity_df.withColumn(\"sentiment\", \n",
    "                                                when(polarity_df.polarity > 0, 'positive')\n",
    "                                                .when(polarity_df.polarity < 0, 'negative')\n",
    "                                                .otherwise('neutral')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discrepancy between review sentiment and review rating\n",
    "In some cases, sentiment expressed in review may not match with star rating. For instance, positive sentiment is expressed in the review, but rated as 1 or 2 star (negative). We need to investigate such cases further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">14</span><span class=\"ansired\">]: </span>135490</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Count of reviews where sentiment and rating does not match\n",
    "polarity_df.filter(polarity_df[\"sentiment\"] != polarity_df[\"review_category\"]).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">15</span><span class=\"ansired\">]: </span>0.2302704815642553</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "135490/588395"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">16</span><span class=\"ansired\">]: </span>36310</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Count of reviews where sentiment is positive but rating is negative\n",
    "polarity_df.filter(\"sentiment = 'positive'\").filter(\"review_category = 'negative'\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">17</span><span class=\"ansired\">]: </span>22431</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Count of reviews where sentiment is negative but rating is positive\n",
    "polarity_df.filter(\"sentiment = 'negative'\").filter(\"review_category = 'positive'\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almost in 23% of the cases, sentiment expressed in the review does not match with star_rating. Some of these cases could be where rating is positive or negative, but review is so short or subjective that its sentiment is determined to be neutral. There are also as many as 36,310 cases where sentiment expressed in positive, but rated as negative. But we need to further investigate this as to whether there is real discrepancy or this is an artifact of text cleaning. It is also possible that, textblob fails to identify sentiment correctly in some cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_body</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>review_category</th>\n",
       "      <th>polarity</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>excellent  stars</td>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.00</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>there is nobody in this story that is likeable the story does not have a very good or beleiveable plot</td>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.91</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>you don t have to read this book it s a sort of corporation promotion of self help books don t confuse it with any of the excellent books about books that you might be reading instead ugh</td>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.00</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>stars grisham is the best</td>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.00</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>not her best work</td>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.00</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>the book is a very good book it is something that every one can read take some time and read the book</td>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.91</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>i didn t like it and don t recommend anyone to buy i just bought a refurbished version and according to its description it should be in very good condition but it s in very fair condition unacceptable i will attach some pics of it</td>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.91</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>not the best quality already peeling off</td>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.00</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>not the best material go for the iblason prime</td>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.00</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>excellent</td>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.00</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>i could not use this phone because it s was boost mobile carrier furthermore the conditions was excellent condition i m a buyer from venezuela this is a prepaid phone it s not going to work in venezuela</td>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.00</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>not the best case</td>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.00</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>when i attached it to my car it was very good but when it was detached i couldn t use it again</td>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.91</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>i gave this item  star not based on performance but because i found out after taking the item to best buy to have it installed that it could not be installed in my  cadillac srx it could not be installed because the  cadillac srx has no structure in the roof to support the item i have decided to consider installing headrest dvd players instead</td>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.00</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>wonderful music</td>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.00</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>it works for the nook color but not as wonderful as everyone else says</td>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.00</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>will throw away cannot connect with router bought a d link which works perfectly</td>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.00</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>best one i have ever bought i have  ipad s for work bussiness</td>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.00</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>it looked just like the picture and it had the features my son was looking for he was very happy when he received it</td>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.00</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>excellent</td>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.00</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>i thought this was going to show me how to work the pole instead it just a bunch of interview with canadian strippers no blakc girls at all so misleading but the product came in excellent condition</td>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.00</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>wasn t looking forward to going here but maybe i can do this wish me best of luck thank you suzanne</td>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.00</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>i completes a set i started for my daughter in law that i know will become a keepsake and price as very good l</td>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.91</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>this was just perfect for me because i needed it for a compact car i just purchased it holds any quantity and doesn t spill packs away discreetly and even has eye appeal with the color and shape</td>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.00</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>i literraly did not lose one pound and have been taking it as directed with a colon cleanser for proposed best results</td>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.00</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>this can opener is of dollar store quality at best i would not recommend this product to anyone</td>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.00</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>mmmmm perfect</td>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.00</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>it had no scent and produced no lather it was nothing like their wonderful soap i bought  bottles and gave one away</td>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.00</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>hornady s customer service is awesome but their  whisper dies are junk sizing dies breaks about every  shells the sizing rod strips out</td>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.00</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>was and awesome design but was s ty metal rusted a week after having it i would not recommend anyone to buy the ever</td>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.00</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>this didn t antenna didn t work for me at all could be i am not in the best area to receive reception i didn t get  channel</td>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.00</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>it s just a piece of felt with the plastic sleeves stuck in it i could have made this myself not the best quality</td>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.00</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>best to research before buying and saying it ll work in my  gp</td>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.00</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>not the best radio reception</td>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.00</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>excellent</td>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.00</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>pepper loves all your flavors they are wonderful</td>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.00</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>my software support people are sold on these printers they never work as promised i returned and bought a mono hp laser printer hp works perfectly</td>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.00</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>a very good item</td>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.91</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>the home ants tried their best to avoid the container and when i dropped out some liquid on the ants route they will circle away the drops but will never touch it what is the use of this bait if the ants feels yucky about it</td>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.00</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>the belt arrived promptly and worked perfectly</td>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.00</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>excellent what i was expecting</td>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.00</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>i bought this controller and it worked perfectly for about a week then it just wouldn t turn on wouldn t respond to being plugged in it was done i had to go to gamestop and buy a used one for  do not buy this</td>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.00</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>price was exorbitant i did not pay attention to it when i ordered also don t taste very good</td>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.91</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>this will be perfect for car rides</td>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.00</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>didn t like the quality cut customer service was very good</td>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.91</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>not what i thought they would be using them in guest bathroom not the best quality</td>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.00</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>all these items i purchased are excellent</td>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.00</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Reviews where sentiment is highly positive but rating is highly negative\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "discrepancy_df = polarity_df.filter(\"polarity > 0.9\").filter(\"star_rating = 1\")\n",
    "discrepancy_df.limit(47).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">19</span><span class=\"ansired\">]: </span>586154</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Investigate one of the reviews further\n",
    "review_body_list_2.index(\"all these items i purchased are excellent \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">20</span><span class=\"ansired\">]: </span>&apos;All these items I purchased are excellent.&apos;</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get the pre-cleaned version of the above review.\n",
    "review_body_list[586154]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">21</span><span class=\"ansired\">]: </span>509879</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Investigate one more review further\n",
    "review_body_list_2.index(\"i bought this controller and it worked perfectly for about a week then it just wouldn t turn on wouldn t respond to being plugged in it was done i had to go to gamestop and buy a used one for  do not buy this \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">22</span><span class=\"ansired\">]: </span>&quot;I bought this controller, and it worked perfectly...for about a week. Then it just wouldn&apos;t turn on, wouldn&apos;t respond to being plugged in, it was done. I had to go to Gamestop and buy a used one for $50. DO NOT BUY THIS.&quot;</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get the pre-cleaned version of the above review.\n",
    "review_body_list[509879]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">23</span><span class=\"ansired\">]: </span>0.35</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## The following is quite negative review. But text blob assigned a positive polarity (0.35).\n",
    "TextBlob('The book was in perfect condition, but the access code, which is the most important part, did not work. Since I purchased this from Amazon, Cengage was unable to assist me. I do not recommend buying this.').polarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen above, there are possibly many reviews that are mislabelled (e.g., review is positive, but rating is negative). Take a look at the following review for example,\n",
    "\n",
    "**\"All these items I purchased are excellent.\"**\n",
    "\n",
    "The review is definitely positve, but the reviewer rated it with one star.\n",
    "\n",
    "So I originally, I thought of removing all reviews where rating does not match with setniment (as determined by textblob) expressed in the review. However, textblob assignment of sentiment is not accurate either. Take a look at the following review;\n",
    "\n",
    "**\"I bought this controller, and it worked perfectly...for about a week. Then it just wouldn't turn on, wouldn't respond to being plugged in, it was done. I had to go\n",
    "to Gamestop and buy a used one for $50. DO NOT BUY THIS.\"**\n",
    "\n",
    "This is definitely a negative review, but textblob assigned a polarity of 1 (highly positive sentiment)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='dv'></a>\n",
    "## Doc2Vec\n",
    "Apache Spark does not provide an API for ‘Doc2Vec’. But its ‘Word2Vec’ transformer based on the ‘Skip-Gram’ approach, can be used as Doc2Vec. `The Word2VecModel transforms each document into a vector using the average of all words in the document` ([Apache Spark Documentation](https://spark.apache.org/docs/latest/ml-features.html#word2vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.ml.feature import Word2Vec\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(inputCol=\"review_body\", outputCol=\"tokens\")\n",
    "word2vec = Word2Vec(vectorSize=300, minCount=0, inputCol=\"tokens\", outputCol=\"features\")\n",
    "doc2vec_pipeline = Pipeline(stages=[tokenizer, word2vec])\n",
    "doc2vec_model = doc2vec_pipeline.fit(clean_review_rating_helpful_df)\n",
    "doc2vecs_df = doc2vec_model.transform(clean_review_rating_helpful_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='rp'></a>\n",
    "## ML Prototyping: Rating Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "# Encode the target label\n",
    "string_indexer = StringIndexer(inputCol=\"review_category\", outputCol=\"label\")\n",
    "doc2vecs_df_encoded = string_indexer.fit(doc2vecs_df).transform(doc2vecs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Split the data into train and test set\n",
    "train_set, test_set = doc2vecs_df_encoded.randomSplit([0.7, 0.3], seed=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "import pandas as pd\n",
    "\n",
    "# A function to get performance metrics\n",
    "def print_performance_metrics(predictions):\n",
    "  # Get accuracy of the model\n",
    "  model_evaluator = MulticlassClassificationEvaluator(\n",
    "      labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "  accuracy = model_evaluator.evaluate(predictions)\n",
    "  print(\"Accuracy: {:.3f}\\n\".format(accuracy))\n",
    "\n",
    "  # get rdd of predictions and labels for eval metrics\n",
    "  predictionAndLabels = predictions.select(\"prediction\",\"label\").rdd\n",
    "\n",
    "  # Instantiate metrics objects\n",
    "  multi_metrics = MulticlassMetrics(predictionAndLabels)\n",
    "  # Get confusion matrix\n",
    "  cm = multi_metrics.confusionMatrix()\n",
    "  print (\"Confusion Metrix:\")\n",
    "  print(cm)\n",
    "  print (\"\\nConfusion Metrix as a Pandas Dataframe:\")\n",
    "  print(pd.DataFrame(cm.toArray().tolist(), columns=['predicted_pos', 'predicted_neg', 'predicted_neu'], index=['actual_pos', 'actual_neg', 'actual_neu']))\n",
    "  print(\"\\nFraction of positive reviews correctly predicted as positive (recall): {:.3f}\".format(cm[0,0]/(cm[0,0] + cm[0,1] + cm[0,2])))\n",
    "  print(\"\\nFraction of negative reviews correctly predicted as negative (recall): {:.3f}\".format(cm[1,1]/(cm[1,0] + cm[1,1] + cm[1,2])))\n",
    "  print(\"\\nFraction of neutral reviews correctly predicted as neutral (recall): {:.3f}\".format(cm[2,2]/(cm[2,0] + cm[2,1] + cm[2,2])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='lr'></a>\n",
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Accuracy: 0.849\n",
       "\n",
       "Confusion Metrix:\n",
       "DenseMatrix([[136732.,   2607.,    947.],\n",
       "             [  9385.,  11936.,    477.],\n",
       "             [ 10771.,   2507.,    950.]])\n",
       "\n",
       "Confusion Metrix as a Pandas Dataframe:\n",
       "            predicted_pos  predicted_neg  predicted_neu\n",
       "actual_pos  136732.0       2607.0         947.0        \n",
       "actual_neg  9385.0         11936.0        477.0        \n",
       "actual_neu  10771.0        2507.0         950.0        \n",
       "\n",
       "Fraction of positive reviews correctly predicted as positive (recall): 0.975\n",
       "\n",
       "Fraction of negative reviews correctly predicted as negative (recall): 0.548\n",
       "\n",
       "Fraction of neutral reviews correctly predicted as neutral (recall): 0.067\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fit the model and get the predictions for test set\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "# Instantiate a logistic regression classifier\n",
    "lr = LogisticRegression(labelCol=\"label\", featuresCol=\"features\")\n",
    "# Fit train set\n",
    "lr_model = lr.fit(train_set)\n",
    "# Predict test set\n",
    "lr_predictions = lr_model.transform(test_set)\n",
    "# Print performance metrics of logistic regression\n",
    "print_performance_metrics(lr_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression with Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">/databricks/spark/python/pyspark/ml/util.py:791: UserWarning: Can not find mlflow. To enable mlflow logging, install MLflow library from PyPi.\n",
       "  warnings.warn(_MLflowInstrumentation._NO_MLFLOW_WARNING)\n",
       "0.01\n",
       "0.0\n",
       "100\n",
       "Accuracy: 0.849\n",
       "\n",
       "Confusion Metrix:\n",
       "DenseMatrix([[136732.,   2607.,    947.],\n",
       "             [  9385.,  11936.,    477.],\n",
       "             [ 10771.,   2507.,    950.]])\n",
       "\n",
       "Confusion Metrix as a Pandas Dataframe:\n",
       "            predicted_pos  predicted_neg  predicted_neu\n",
       "actual_pos  136732.0       2607.0         947.0        \n",
       "actual_neg  9385.0         11936.0        477.0        \n",
       "actual_neu  10771.0        2507.0         950.0        \n",
       "\n",
       "Fraction of positive reviews correctly predicted as positive (recall): 0.975\n",
       "\n",
       "Fraction of negative reviews correctly predicted as negative (recall): 0.548\n",
       "\n",
       "Fraction of neutral reviews correctly predicted as neutral (recall): 0.067\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "\n",
    "# Instantiate a classifier\n",
    "lr = LogisticRegression(labelCol=\"label\", featuresCol=\"features\")\n",
    "\n",
    "# Perform gridsearch cv\n",
    "lrParamGrid = (ParamGridBuilder()\n",
    "               .addGrid(lr.regParam, [0.01, 0.5, 2.0])\n",
    "               .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0])\n",
    "               .addGrid(lr.maxIter, [10, 100])\n",
    "               .build())\n",
    "\n",
    "# set up an evaluator\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "      labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "\n",
    "# Create CrossValidator\n",
    "lrCv = CrossValidator(estimator=lr, estimatorParamMaps=lrParamGrid, evaluator=evaluator, numFolds=3)\n",
    "\n",
    "#Run cross validations\n",
    "lrCvModel = lrCv.fit(train_set)\n",
    "\n",
    "# # Look at best params from the CV\n",
    "print(lrCvModel.bestModel._java_obj.getRegParam())\n",
    "print(lrCvModel.bestModel._java_obj.getElasticNetParam())\n",
    "print(lrCvModel.bestModel._java_obj.getMaxIter())\n",
    "\n",
    "# Get prediction\n",
    "lrCvPredictions = lrCvModel.transform(test_set)\n",
    "\n",
    "# Print performance metrics of logistic regression with cross validation\n",
    "print_performance_metrics(lr_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='rf'></a>\n",
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">32</span><span class=\"ansired\">]: </span>DataFrame[review_body: string, star_rating: bigint, helpful_votes: bigint, total_votes: bigint, review_category: string, tokens: array&lt;string&gt;, features: vector]</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc2vecs_df.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Accuracy: 0.796\n",
       "\n",
       "Confusion Metrix:\n",
       "DenseMatrix([[140286.,      0.,      0.],\n",
       "             [ 21798.,      0.,      0.],\n",
       "             [ 14228.,      0.,      0.]])\n",
       "\n",
       "Confusion Metrix as a Pandas Dataframe:\n",
       "            predicted_pos  predicted_neg  predicted_neu\n",
       "actual_pos  140286.0       0.0            0.0          \n",
       "actual_neg  21798.0        0.0            0.0          \n",
       "actual_neu  14228.0        0.0            0.0          \n",
       "\n",
       "Fraction of positive reviews correctly predicted as positive (recall): 1.000\n",
       "\n",
       "Fraction of negative reviews correctly predicted as negative (recall): 0.000\n",
       "\n",
       "Fraction of neutral reviews correctly predicted as neutral (recall): 0.000\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "# Instantiate a random forest classifier\n",
    "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\", subsamplingRate=0.5, numTrees=500)\n",
    "# Fit train set\n",
    "rf_model = rf.fit(train_set)\n",
    "# Predict test set\n",
    "rf_predictions = rf_model.transform(test_set)\n",
    "# Print performance metrics of random forest\n",
    "print_performance_metrics(rf_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest with Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">2\n",
       "20\n",
       "Accuracy: 0.796\n",
       "\n",
       "Confusion Metrix:\n",
       "DenseMatrix([[140286.,      0.,      0.],\n",
       "             [ 21798.,      0.,      0.],\n",
       "             [ 14228.,      0.,      0.]])\n",
       "\n",
       "Confusion Metrix as a Pandas Dataframe:\n",
       "            predicted_pos  predicted_neg  predicted_neu\n",
       "actual_pos  140286.0       0.0            0.0          \n",
       "actual_neg  21798.0        0.0            0.0          \n",
       "actual_neu  14228.0        0.0            0.0          \n",
       "\n",
       "Fraction of positive reviews correctly predicted as positive (recall): 1.000\n",
       "\n",
       "Fraction of negative reviews correctly predicted as negative (recall): 0.000\n",
       "\n",
       "Fraction of neutral reviews correctly predicted as neutral (recall): 0.000\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "\n",
    "# Instantiate a classifier\n",
    "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\", subsamplingRate=0.5)\n",
    "\n",
    "# Perform gridsearch cv\n",
    "rfParamGrid = (ParamGridBuilder()\n",
    "               .addGrid(rf.maxDepth, [2, 5])\n",
    "               .addGrid(rf.numTrees, [20, 40])\n",
    "               .build())\n",
    "\n",
    "# set up an evaluator\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "      labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "\n",
    "# Create CrossValidator\n",
    "rfCv = CrossValidator(estimator=rf, estimatorParamMaps=rfParamGrid, evaluator=evaluator, numFolds=3)\n",
    "\n",
    "# Run cross validations\n",
    "rfCvModel = rfCv.fit(train_set)\n",
    "\n",
    "# # Look at best params from the CV\n",
    "print(rfCvModel.bestModel._java_obj.getMaxDepth())\n",
    "print(rfCvModel.bestModel._java_obj.getNumTrees())\n",
    "\n",
    "# Get prediction\n",
    "rfCvPredictions = rfCvModel.transform(test_set)\n",
    "\n",
    "# Print performance of Random Forest classifier\n",
    "print_performance_metrics(rfCvPredictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='mlp'></a>\n",
    "### Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "\n",
    "# # Instantiate a random forest classifier\n",
    "# layers = [300, 150, 75, 3]\n",
    "# mlp = MultilayerPerceptronClassifier(labelCol=\"label\", featuresCol=\"features\", layers=layers)\n",
    "# # Fit train set\n",
    "# mlp_model = mlp.fit(train_set)\n",
    "# # Predict test set\n",
    "# mlp_predictions = mlp_model.transform(test_set)\n",
    "# # Print performance metrics of random forest\n",
    "# print_performance_metrics(mlp_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ci'></a>\n",
    "## Dealing with Class Imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the problems with this dataset is class imbalance. The class distribution is as follow.\n",
    "\n",
    "- Positive - 80%\n",
    "- Negative - 12%\n",
    "- Neutral - 8%\n",
    "\n",
    "Positive class is way more than negative and neutral class. This negatively affect model performance in correctly predicting rare class to the extent that in classifier like random forest above, it simply predicted every smaple to be positive. To overcometime, in PySpark, in the case of logistic regression we have a technique called “Class Weighing”, wherein class weight is set to be inversly proportional to its frequency. \n",
    "\n",
    "However, for random forest we do not have such class weighing parameter in PySpark. So for random forest, I have downsampled the positive class (only 16% of positive class data is used). I opted for downsampling as the dataset is huge with more than 100 million rows, so downsampling should not affect training much."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ilr'></a>\n",
    "### Logistic Regression with Class Weight Balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get the count of review categories\n",
    "train_count = train_set.groupby(\"review_category\").count().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">37</span><span class=\"ansired\">]: </span>(0.05725040129479161, 0.3718113047303265, 0.5709382939748819)</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get the class weight based on its frequency\n",
    "pos_count = train_count.iloc[0,1]\n",
    "neu_count = train_count.iloc[1,1]\n",
    "neg_count = train_count.iloc[2,1]\n",
    "\n",
    "inv_pos = 1/pos_count\n",
    "inv_neg = 1/neg_count\n",
    "inv_neu = 1/neu_count\n",
    "\n",
    "pos_weight = 1/(pos_count * (inv_pos +  inv_neg + inv_neu))\n",
    "neg_weight = 1/(neg_count * (inv_pos +  inv_neg + inv_neu))\n",
    "neu_weight = 1/(neu_count * (inv_pos +  inv_neg + inv_neu))\n",
    "(pos_weight, neg_weight, neu_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create a classWeight column in trainset\n",
    "train_set_2=(train_set.withColumn(\"classWeight\", when(train_set.review_category == 'positive', pos_weight)\n",
    "                          .when(train_set.review_category == 'negative', neg_weight)\n",
    "                          .otherwise(neu_weight)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Accuracy: 0.733\n",
       "\n",
       "Confusion Metrix:\n",
       "DenseMatrix([[105520.,   8972.,  25794.],\n",
       "             [  1409.,  15417.,   4972.],\n",
       "             [  2441.,   3533.,   8254.]])\n",
       "\n",
       "Confusion Metrix as a Pandas Dataframe:\n",
       "            predicted_pos  predicted_neg  predicted_neu\n",
       "actual_pos  105520.0       8972.0         25794.0      \n",
       "actual_neg  1409.0         15417.0        4972.0       \n",
       "actual_neu  2441.0         3533.0         8254.0       \n",
       "\n",
       "Fraction of positive reviews correctly predicted as positive (recall): 0.752\n",
       "\n",
       "Fraction of negative reviews correctly predicted as negative (recall): 0.707\n",
       "\n",
       "Fraction of neutral reviews correctly predicted as neutral (recall): 0.580\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fit the model and get the predictions for test set\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "# Instantiate a logistic regression classifier. Deafault parameters can be used as parameter tuning did not improve performance.\n",
    "lrb = LogisticRegression(labelCol=\"label\", featuresCol=\"features\", weightCol='classWeight')\n",
    "# Fit train set\n",
    "lrb_model = lrb.fit(train_set_2)\n",
    "# Predict test set\n",
    "lrb_predictions = lrb_model.transform(test_set)\n",
    "# Print performance metrics of logistic regression\n",
    "print_performance_metrics(lrb_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='irf'></a>\n",
    "### Random Forest with Balanced Dataset\n",
    "Since there is no built-in parameter in PySpark Random Forest to handle imbalanced data, I have downsampled the positive class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# sub sample only 16% of data with positive label and all of data with negative and neutral samples\n",
    "sample_frac = 0.16\n",
    "# Filter rows with positve class\n",
    "doc2vecs_df_pos = doc2vecs_df.filter(\"review_category = 'positive'\")\n",
    "# Sample 20% of positive class\n",
    "doc2vecs_df_pos_sample = doc2vecs_df_pos.sample(False, sample_frac, 42)\n",
    "# Filter negative and neutral rows\n",
    "doc2vecs_df_neg_neu = doc2vecs_df.filter(\"review_category != 'positive'\")\n",
    "# Combine smapled positive rows with negative and neutral rows\n",
    "doc2vecs_df_balanced = doc2vecs_df_pos_sample.union(doc2vecs_df_neg_neu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.functions import rand\n",
    "# Shuffle the data\n",
    "doc2vecs_df_balanced = doc2vecs_df_balanced.orderBy(rand())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "# Encode the target label\n",
    "string_indexer = StringIndexer(inputCol=\"review_category\", outputCol=\"label\")\n",
    "doc2vecs_df_balanced_encoded = string_indexer.fit(doc2vecs_df_balanced).transform(doc2vecs_df_balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Split the data into train and test set\n",
    "train_set_b, test_set_b = doc2vecs_df_balanced_encoded.randomSplit([0.7, 0.3], seed=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Accuracy: 0.607\n",
       "\n",
       "Confusion Metrix:\n",
       "DenseMatrix([[17168.,  5039.,     0.],\n",
       "             [ 3720., 17946.,     0.],\n",
       "             [ 5276.,  8868.,     0.]])\n",
       "\n",
       "Confusion Metrix as a Pandas Dataframe:\n",
       "            predicted_pos  predicted_neg  predicted_neu\n",
       "actual_pos        17168.0         5039.0            0.0\n",
       "actual_neg         3720.0        17946.0            0.0\n",
       "actual_neu         5276.0         8868.0            0.0\n",
       "\n",
       "Fraction of positive reviews correctly predicted as positive (recall): 0.773\n",
       "\n",
       "Fraction of negative reviews correctly predicted as negative (recall): 0.828\n",
       "\n",
       "Fraction of neutral reviews correctly predicted as neutral (recall): 0.000\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "# Instantiate a random forest classifier\n",
    "rfb = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\", subsamplingRate=0.5, numTrees=500)\n",
    "# Fit train set\n",
    "rfb_model = rfb.fit(train_set_b)\n",
    "# Predict test set\n",
    "rfb_predictions = rfb_model.transform(test_set_b)\n",
    "# Print performance metrics of random forest\n",
    "print_performance_metrics(rfb_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='imlp'></a>\n",
    "### Multilayer Perceptron with Balanced Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Accuracy: 0.692\n",
       "\n",
       "Confusion Metrix:\n",
       "DenseMatrix([[18317.,  2223.,  1744.],\n",
       "             [ 1980., 17466.,  2278.],\n",
       "             [ 3745.,  5751.,  4444.]])\n",
       "\n",
       "Confusion Metrix as a Pandas Dataframe:\n",
       "            predicted_pos  predicted_neg  predicted_neu\n",
       "actual_pos        18317.0         2223.0         1744.0\n",
       "actual_neg         1980.0        17466.0         2278.0\n",
       "actual_neu         3745.0         5751.0         4444.0\n",
       "\n",
       "Fraction of positive reviews correctly predicted as positive (recall): 0.822\n",
       "\n",
       "Fraction of negative reviews correctly predicted as negative (recall): 0.804\n",
       "\n",
       "Fraction of neutral reviews correctly predicted as neutral (recall): 0.319\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "\n",
    "# Instantiate a random forest classifier\n",
    "layers = [300, 150, 75, 3]\n",
    "mlpb = MultilayerPerceptronClassifier(labelCol=\"label\", featuresCol=\"features\", layers=layers)\n",
    "# Fit train set\n",
    "mlpb_model = mlpb.fit(train_set_b)\n",
    "# Predict test set\n",
    "mlpb_predictions = mlpb_model.transform(test_set_b)\n",
    "# Print performance metrics of random forest\n",
    "print_performance_metrics(mlpb_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='hp'></a>\n",
    "## ML Prototyping: Helpfulness Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helpfulness index\n",
    "Absolute number of helpful votes is not suitable for comparison because of varying number of total votes among different reviews. For instance, a review with 15 helpful votes out of 10,000 total votes must be less helpful than a review with 10 helpful votes out of 11 total votes. To deal with this issue, a new helpful_index has been created by dividing helpful_votes by total_votes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subset Review with More Than Five Total Votes\n",
    "It is tricky to analyze the total and helpful votes as most of the reveiws has 0 total votes. Furthermore, very low total votes may bias the analysis. For instance if there is only one total vote and if it is voted as helpful, it works out to a helpful_index of 1, which may or may not be reliable. To circumvent this problem, only reviews with more than 5 total votes are taken into consideration for this analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc2vecs_helpful_df = doc2vecs_df.filter(doc2vecs_df[\"total_votes\"] > 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">22</span><span class=\"ansired\">]: </span>34831</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc2vecs_helpful_df = (doc2vecs_helpful_df.\n",
    "                    withColumn('helpful_index', doc2vecs_helpful_df.helpful_votes/doc2vecs_helpful_df.total_votes))\n",
    "(doc2vecs_helpful_df.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='lrg'></a>\n",
    "### Linear Regression with Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Split the data into train and test set\n",
    "train_set_h, test_set_h = doc2vecs_helpful_df.randomSplit([0.7, 0.3], seed=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">/databricks/spark/python/pyspark/ml/util.py:791: UserWarning: Can not find mlflow. To enable mlflow logging, install MLflow library from PyPi.\n",
       "  warnings.warn(_MLflowInstrumentation._NO_MLFLOW_WARNING)\n",
       "0.01\n",
       "0.0\n",
       "100\n",
       "RMSE on the test set: 0.250\n",
       "R2 on the test set: 0.202\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Instantiate a classifier\n",
    "lrg = LinearRegression(labelCol=\"helpful_index\", featuresCol=\"features\")\n",
    "\n",
    "# Perform gridsearch cv\n",
    "lrgParamGrid = (ParamGridBuilder()\n",
    "               .addGrid(lrg.regParam, [0, 0.01, 0.5, 2.0])\n",
    "               .addGrid(lrg.elasticNetParam, [0.0, 0.5, 1.0])\n",
    "               .addGrid(lrg.maxIter, [100,200])\n",
    "               .build())\n",
    "\n",
    "# set up an evaluator\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=lrg.getLabelCol(), predictionCol=lrg.getPredictionCol())\n",
    "\n",
    "# Create CrossValidator\n",
    "lrgCv = CrossValidator(estimator=lrg, estimatorParamMaps=lrgParamGrid, evaluator=evaluator)\n",
    "\n",
    "#Run cross validations\n",
    "lrgCvModel = lrgCv.fit(train_set_h)\n",
    "\n",
    "# # Look at best params from the CV\n",
    "print(lrgCvModel.bestModel._java_obj.getRegParam())\n",
    "print(lrgCvModel.bestModel._java_obj.getElasticNetParam())\n",
    "print(lrgCvModel.bestModel._java_obj.getMaxIter())\n",
    "\n",
    "# Get prediction\n",
    "lrgCvPredictions = lrgCvModel.transform(test_set_h)\n",
    "\n",
    "# Print evaluation metrics\n",
    "# Print rmse\n",
    "rmse = evaluator.evaluate(lrgCvPredictions)\n",
    "print (\"RMSE on the test set: {:.3f}\".format(rmse))\n",
    "\n",
    "# Print R2\n",
    "r2 = RegressionEvaluator(metricName=\"r2\", labelCol=lrg.getLabelCol(), predictionCol=lrg.getPredictionCol()).evaluate(lrgCvPredictions)\n",
    "print (\"R2 on the test set: {:.3f}\".format(r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">RMSE on the test set: 0.249\n",
       "R2 on the test set: 0.206\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Instantiate a classifier\n",
    "lrg = LinearRegression(labelCol=\"helpful_index\", featuresCol=\"features\", maxIter=1000, regParam=0.05)\n",
    "\n",
    "# Fit training Data\n",
    "lrgModel = lrg.fit(train_set_h)\n",
    "\n",
    "# Get prediction\n",
    "lrgPredictions = lrgModel.transform(test_set_h)\n",
    "\n",
    "# Print evaluation metrics\n",
    "# Print rmse\n",
    "rmse = RegressionEvaluator(metricName=\"rmse\", labelCol=lrg.getLabelCol(), predictionCol=lrg.getPredictionCol()).evaluate(lrgPredictions)\n",
    "print (\"RMSE on the test set: {:.3f}\".format(rmse))\n",
    "\n",
    "# Print R2\n",
    "r2 = RegressionEvaluator(metricName=\"r2\", labelCol=lrg.getLabelCol(), predictionCol=lrg.getPredictionCol()).evaluate(lrgPredictions)\n",
    "print (\"R2 on the test set: {:.3f}\".format(r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">r2 if we just predict mean of the helpful_index for all reviews: 1.1102230246251565e-15\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# What would be the R2, if we just predict mean of the helpful_index for all reviews.\n",
    "mean_help_df = lrgPredictions.select('helpful_index')\n",
    "from pyspark.sql.functions import lit\n",
    "mean_ = mean_help_df.groupBy().avg(\"helpful_index\").take(1)[0][0]\n",
    "mean_help_df = mean_help_df.withColumn(\"mean_helpful_index\", lit(mean_))\n",
    "r2_mean = RegressionEvaluator(metricName=\"r2\", labelCol='helpful_index', predictionCol='mean_helpful_index').evaluate(mean_help_df)\n",
    "print(\"r2 if we just predict mean of the helpful_index for all reviews: {}\".format(r2_mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='gbt'></a>\n",
    "### Gradient Boosting Tree with Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "# from pyspark.ml.regression import GBTRegressor\n",
    "# from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# # Instantiate a classifier\n",
    "# gbt = GBTRegressor(labelCol=\"helpful_index\", featuresCol=\"features\")\n",
    "\n",
    "# # Perform gridsearch cv\n",
    "# gbtParamGrid = (ParamGridBuilder()\n",
    "#                .addGrid(gbt.maxDepth, [2, 5])\n",
    "#                .addGrid(gbt.maxIter, [20,100])\n",
    "#                .build())\n",
    "\n",
    "# # set up an evaluator\n",
    "# evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=gbt.getLabelCol(), predictionCol=gbt.getPredictionCol())\n",
    "\n",
    "# # Create CrossValidator\n",
    "# gbtCv = CrossValidator(estimator=gbt, estimatorParamMaps=gbtParamGrid, evaluator=evaluator)\n",
    "\n",
    "# #Run cross validations\n",
    "# gbtCvModel = gbtCv.fit(train_set_h)\n",
    "\n",
    "# # # Look at best params from the CV\n",
    "# print(gbtCvModel.bestModel._java_obj.getMaxDepth())\n",
    "# print(gbtCvModel.bestModel._java_obj.getMaxIter())\n",
    "\n",
    "# # Get prediction\n",
    "# gbtCvPredictions = gbtCvModel.transform(test_set_h)\n",
    "\n",
    "# # Print evaluation metrics\n",
    "# # Print rmse\n",
    "# rmse = evaluator.evaluate(gbtCvPredictions)\n",
    "# print (\"RMSE on the test set: {:.3f}\".format(rmse))\n",
    "\n",
    "# # Print R2\n",
    "# r2 = RegressionEvaluator(metricName=\"r2\", labelCol=gbt.getLabelCol(), predictionCol=gbt.getPredictionCol()).evaluate(gbtCvPredictions)\n",
    "# print (\"R2 on the test set: {:.3f}\".format(r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">RMSE on the test set: 0.246\n",
       "R2 on the test set: 0.224\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.ml.regression import GBTRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Instantiate a classifier\n",
    "gbt = GBTRegressor(labelCol=\"helpful_index\", featuresCol=\"features\", maxIter=100, maxDepth=5)\n",
    "\n",
    "# Fit training Data\n",
    "gbtModel = gbt.fit(train_set_h)\n",
    "\n",
    "# Get prediction\n",
    "gbtPredictions = gbtModel.transform(test_set_h)\n",
    "\n",
    "# Print evaluation metrics\n",
    "# Print rmse\n",
    "rmse = RegressionEvaluator(metricName=\"rmse\", labelCol=gbt.getLabelCol(), predictionCol=gbt.getPredictionCol()).evaluate(gbtPredictions)\n",
    "print (\"RMSE on the test set: {:.3f}\".format(rmse))\n",
    "\n",
    "# Print R2\n",
    "r2 = RegressionEvaluator(metricName=\"r2\", labelCol=gbt.getLabelCol(), predictionCol=gbt.getPredictionCol()).evaluate(gbtPredictions)\n",
    "print (\"R2 on the test set: {:.3f}\".format(r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='cl'></a>\n",
    "## Conclusion\n",
    "\n",
    "I have used three different algorithms - Logistic Regression, Random Forest and Multilayer Perceptron (MLP) - to predict star rating. Considering the accuracy and recall of positive, negative and neutal review classes and training time, I am planning to use Logistic Regression while scaling the ML model. The following is the performance metrics of this model:\n",
    "\n",
    "- Accuracy: 73%\n",
    "- Positive class recall: 75%\n",
    "- Negative class recall: 70%\n",
    "- Neutral class recall: 58%\n",
    "\n",
    "\n",
    "Although MLP produced better recall with positive (82%) and negative classes (80%), its overall accuracy (69%) is less than that of Logistic Regression. To train,  Logistic Regression took just ~3 minutes, while MLP took ~49 minutes.\n",
    "\n",
    "I used two different algorithms - Linear Regression and Gradient Boosting Trees - for predicting helpfullness. Linear regression and Gradient Boosting Trees produced an R2 of ~21 and 22%, respectively."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "name": "ml_model_prototyping",
  "notebookId": 1176100550134691
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
